{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, MaxPooling2D, Dense, Conv1D, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io as sio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = sio.loadmat(\"data/mnist.mat\")\n",
    "X = mnist['X']\n",
    "labels = mnist['labels']\n",
    "data = X\n",
    "#data = np.transpose(data, [2, 0, 1])\n",
    "data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "data = data.T\n",
    "\n",
    "catlabels = to_categorical(labels)\n",
    "\n",
    "trainingsize = 1000\n",
    "\n",
    "test = data[trainingsize:, :]\n",
    "testl = labels[trainingsize:].flatten()\n",
    "training = data[:trainingsize, :, ]\n",
    "trainingl = catlabels[:trainingsize]\n",
    "print(training.shape, trainingl.shape)\n",
    "\n",
    "input_shape = (28 * 28,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1000/1000 [==============================] - 1s 735us/sample - loss: 1.4905 - acc: 0.6360\n",
      "Epoch 2/12\n",
      "1000/1000 [==============================] - 0s 212us/sample - loss: 0.7420 - acc: 0.8360\n",
      "Epoch 3/12\n",
      "1000/1000 [==============================] - 0s 206us/sample - loss: 0.4992 - acc: 0.8790\n",
      "Epoch 4/12\n",
      "1000/1000 [==============================] - 0s 194us/sample - loss: 0.3872 - acc: 0.9100\n",
      "Epoch 5/12\n",
      "1000/1000 [==============================] - 0s 176us/sample - loss: 0.3079 - acc: 0.9230\n",
      "Epoch 6/12\n",
      "1000/1000 [==============================] - 0s 152us/sample - loss: 0.2518 - acc: 0.9340\n",
      "Epoch 7/12\n",
      "1000/1000 [==============================] - 0s 159us/sample - loss: 0.2105 - acc: 0.9490\n",
      "Epoch 8/12\n",
      "1000/1000 [==============================] - 0s 149us/sample - loss: 0.1708 - acc: 0.9660\n",
      "Epoch 9/12\n",
      "1000/1000 [==============================] - 0s 217us/sample - loss: 0.1479 - acc: 0.9700\n",
      "Epoch 10/12\n",
      "1000/1000 [==============================] - 0s 204us/sample - loss: 0.1246 - acc: 0.9830\n",
      "Epoch 11/12\n",
      "1000/1000 [==============================] - 0s 168us/sample - loss: 0.1011 - acc: 0.9880\n",
      "Epoch 12/12\n",
      "1000/1000 [==============================] - 0s 161us/sample - loss: 0.0878 - acc: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2547c10940>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training, trainingl, batch_size=32, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)\n",
    "result = np.apply_along_axis(np.argmax, 1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'87.52%'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:.2f}%\".format(100 * np.sum(result == labels[trainingsize:].flatten()) / len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = sio.loadmat(\"data/mnist.mat\")\n",
    "X = mnist['X']\n",
    "labels = mnist['labels']\n",
    "data = X\n",
    "data = np.transpose(data, [2, 0, 1])\n",
    "data = data.reshape((*data.shape, 1))\n",
    "\n",
    "catlabels = to_categorical(labels)\n",
    "\n",
    "trainingsize = 1000\n",
    "\n",
    "test = data[trainingsize:, :, :, :]\n",
    "testl = labels[trainingsize:].flatten()\n",
    "training = data[:trainingsize, :, :, :]\n",
    "trainingl = catlabels[:trainingsize]\n",
    "print(training.shape, trainingl.shape)\n",
    "\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, (3, 3), input_shape=input_shape, activation='relu')(inputs)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.3009 - acc: 0.5710\n",
      "Epoch 2/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5307 - acc: 0.8290\n",
      "Epoch 3/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3338 - acc: 0.9060\n",
      "Epoch 4/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2615 - acc: 0.9140\n",
      "Epoch 5/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1803 - acc: 0.9390\n",
      "Epoch 6/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1568 - acc: 0.9490\n",
      "Epoch 7/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1279 - acc: 0.9600\n",
      "Epoch 8/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.0988 - acc: 0.9690\n",
      "Epoch 9/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.0620 - acc: 0.9790\n",
      "Epoch 10/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.0616 - acc: 0.9740\n",
      "Epoch 11/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.0403 - acc: 0.9840\n",
      "Epoch 12/12\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.0416 - acc: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2547d00cc0>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training, trainingl, batch_size=32, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)\n",
    "result = np.apply_along_axis(np.argmax, 1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.94%'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:.2f}%\".format(100 * np.sum(result == labels[trainingsize:].flatten()) / len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
